[{"id":"85dc162ae8f3c2b9bfa480ee7525dc8d","title":"gem5 基本部署","content":"gem5 基本部署本文档介绍如何在 Ubuntu 上部署 gem5，主要是系统调用和全系统模拟两种模式。gem5 的官方文章中介绍了这两种模式的异同，具体可以看下图：\n\n\n系统调用模式（SE，Syscall Emulation）将模拟的指令转化为系统调用，全系统模式（FS，Full System）模拟硬件并在模拟的硬件上建立客户操作系统，能够提供更加底层精细的统计，同时性能会更差。但因其 FS 模式更加全面，因此 FS 模式更常使用，是重点。\n下面给出推荐的环境配置：\n\n\n\n环境\n要求\n原因\n\n\n\nUbuntu\n版本 &gt;=18\n按照官网建议的来，gem5 的版本和 Ubuntu 的版本需要搭配，否则难以编译 gem5；本人使用的是 Ubuntu20.04LTS+gem5 22.0。\n\n\ngem5\n版本 &gt;=20.0\n\n\n\nHost 机\n内存 &gt;=8GB\n编译 gem5 的时候很占内存，内存越大越好\n\n\nHost 机\n硬盘 &gt;=100GB\ngem5 本身、全系统的 img 都不小，还可能创建 swap 分区\n\n\ngem5 SE 模式搭建此步骤建议按照官方文档一步一步走，最后进行 Hello world 测试。也可参考他人的博客。\n依赖安装注意：整个安装过程可能需要等待较长时间。切记不要换源，阿里源、清华源均不可，否则会出现难以琢磨的未满足的依赖关系的问题。\n执行下面的命令安装依赖：\nbashsudo apt install build-essential git m4 scons zlib1g zlib1g-dev \\\n    libprotobuf-dev protobuf-compiler libprotoc-dev libgoogle-perftools-dev \\\n    python3-dev python-is-python3 libboost-all-dev pkg-configgem5 源码克隆克隆 gem5 到目录 GEM5 中，要保证空间充足。\nbash# 可以访问谷歌使用下面的克隆，应该是最新版本\ngit clone https://gem5.googlesource.com/public/gem5\n\n# 可以访问github使用下面的克隆，应该是最新版本\ngit clone https://github.com/gem5/gem5.git\n\n# 不能访问上面两种，克隆我本人的公开仓库，版本是22.0\ngit clone https://gitee.com/failurejack/gem5.git编译源码terminal 进入刚刚克隆的 gem5 目录，执行下面命令进行编译：\nbashpython3 `which scons` build/ARM/gem5.opt **-j9**解释一下上面的命令：\n\nARM 代表编译的模拟器的指令集是 arm 指令集，如果要编译 x86 指令集，只需要将 ARM 换成 X86，注意大写。\n-j9 代表编译使用的 CPU 数量为 9，具体的原理我也不太清楚，推荐编译使用的线程数是 CPU 核心数 +1，比如我的 CPU 是 4 核，那就写为 -j5，如果内存不够用，适当调小。\n\n检验是否成功在 gem5 目录中使用 se.py 中的 hello world 测试，控制台打印出 Hello world! 字样证明编译成功：\nbashbuild/**ARM**/gem5.opt configs/example/se.py -c tests/test-progs/hello/bin/**arm**/linux/hello问题：Python 报错编译 gem5 的时候可能出现以下报错：\n\n\n\n\n\n\n\n\n\nEmbedded python library 3.6 or newer requiredChecking for linker -Wl,–as-needed support… yesChecking for compiler -Wno-free-nonheap-object support… yesChecking for compiler -gz support… yesChecking for linker -gz support… yesInfo: Using Python config: python-configChecking for C header file Python.h… yesChecking Python version… 2.7.18Error: Embedded python library 3.6 or newer required, found 2.7.18.\n这里出现问题的可能一方面是版本问题；另一方面可能是 Python 的默认解释器还是 Python2。\n版本问题其实就是 Python 和 SCons 的版本不匹配，按照官方建议的 gem5 版本和 Ubuntu 版本搭配，使用 apt-get 安装的 Python 和 SCons 的版本是匹配的。反过来说不匹配可以在输出中检查并更新（源码编译，添加源都可以）。\n如果本身版本是匹配的，但是仍然编译报错，那就可能是\n这个问题在我初次编译 gem5 的时候遇到过，尽管 Python 的版本都是对的，还是报错，那可能是 Python 的默认解释器还是 Python2，需要手动设置软连接：\nbashcd /usr/bin/\nsudo rm python\nsudo ln -s  python3 python值得注意的是，上述问题在本人第一次编译 gem5 的时候出现过，那时使用的就是 python 的命令，后来使用 python3 的命令编译后，在新的环境中也没有出现过问题。\n问题：内存不足较新版本的 gem5 编译非常占用内存空间，老一些的版本，如大约 2017 年的版本编译需要的内存开销明显较小。最新的 20.0+ 版本需要至少 8GB 以上的内存。\nX86 和 ARM 两个指令集的 gem5 我都编译测试过，在 Ubuntu2004LTS 桌面版中，X86 的编译明显比 ARM 更快而且更节省内存，我在编译 X86 时内存够用，而在编译 ARM 内存不够（8GB 内存），调小 CPU 数也不够，就需要创建 SWAP 分区。创建分区时可能会遇到各种各样的错误 ，可以自行百度解决（这个网上资源非常多）。可以使用下面的命令：\nbash# 从分区/dev/zero向目录/swapfile写入bs*count个字节的空间\nsudo dd if=/dev/zero of=/swapfile bs=1G count=6\n# 把刚才空间格式化成swap格式\nsudo mkswap /swapfile\n# 挂载分区  \nsudo swapon /swapfile如果上面的第一条命令报错：\n\n\n\n\n\n\n\n\n\ndd: failed to open ‘/swapfile’: Text file busy\n则执行 sudo swapoff -a 即可正常运行。\n编译结束后如果硬盘吃紧可以删除该 swap 分区：\nbash# 卸载分区\nsudo swapoff /swapfile\n#删除swap文件，减少空间占用\nsudo rm /swapfilegem5 FS 模式搭建gem5 的 FS 模式需要完全模拟操作系统，因此需要许多组件，基本的组件如下：\n\n\n\n需要组件\n作用\n备注\n\n\n\nkernel\n\n\n\n\nimg\n\n\n\n\nbootloader\n\n\n\n\ndevice tree blob\n\n在 20.0+ 的 gem5 版本中，默认能生成，不需要提供，除非有特殊需求\n\n\n预构建组件对于搭建 ARM 体系的 gem5 全系统模式，并不必要自行创建 kernel 和 disk，直接下载官方预编译的组件即可：\ngem5: Guest Binaries\n后缀中带有 img 的文件一般就是 disk 镜像，其他的则是预编译好的 kernel 和 bootloader 文件（其中有的包含 img）。\n\n\n目前官网上所有预编译文件下载连接如下：\nbash# kernel文件（可能包含img）\nwget [http://dist.gem5.org/dist/v22-0/arm/aarch-system-20220707.tar.bz2](http://dist.gem5.org/dist/v22-0/arm/aarch-system-20220707.tar.bz2)\nwget [http://dist.gem5.org/dist/current/arm/aarch-system-20170616.tar.xz](http://dist.gem5.org/dist/current/arm/aarch-system-20170616.tar.xz)\nwget [http://dist.gem5.org/dist/current/arm/aarch-system-20180409.tar.xz](http://dist.gem5.org/dist/current/arm/aarch-system-20180409.tar.xz)\nwget [http://dist.gem5.org/dist/current/arm/arm-system-dacapo-2011-08.tgz](http://dist.gem5.org/dist/current/arm/arm-system-dacapo-2011-08.tgz)\nwget [http://dist.gem5.org/dist/current/arm/arm-system.tar.bz2](http://dist.gem5.org/dist/current/arm/arm-system.tar.bz2)\nwget [http://dist.gem5.org/dist/current/arm/arm64-system-02-2014.tgz](http://dist.gem5.org/dist/current/arm/arm64-system-02-2014.tgz)\nwget [http://dist.gem5.org/dist/current/arm/kitkat-overlay.tar.bz2](http://dist.gem5.org/dist/current/arm/kitkat-overlay.tar.bz2)\nwget [http://dist.gem5.org/dist/current/arm/linux-arm-arch.tar.bz2](http://dist.gem5.org/dist/current/arm/linux-arm-arch.tar.bz2)\nwget [http://dist.gem5.org/dist/current/arm/vmlinux-emm-pcie-3.3.tar.bz2](http://dist.gem5.org/dist/current/arm/vmlinux-emm-pcie-3.3.tar.bz2)\nwget [http://dist.gem5.org/dist/current/arm/vmlinux.arm.smp.fb.3.2.tar.gz](http://dist.gem5.org/dist/current/arm/vmlinux.arm.smp.fb.3.2.tar.gz)\n\n# img文件\nwget [http://dist.gem5.org/dist/v22-0/arm/disks/ubuntu-18.04-arm64-docker.img.bz2](http://dist.gem5.org/dist/v22-0/arm/disks/ubuntu-18.04-arm64-docker.img.bz2)\nwget [http://dist.gem5.org/dist/v22-0/arm/disks/aarch32-ubuntu-natty-headless.img.bz2](http://dist.gem5.org/dist/v22-0/arm/disks/aarch32-ubuntu-natty-headless.img.bz2)\nwget [http://dist.gem5.org/dist/current/arm/disks/aarch64-ubuntu-trusty-headless.img.bz2](http://dist.gem5.org/dist/current/arm/disks/aarch64-ubuntu-trusty-headless.img.bz2)\nwget [http://dist.gem5.org/dist/current/arm/disks/linaro-minimal-aarch64.img.bz2](http://dist.gem5.org/dist/current/arm/disks/linaro-minimal-aarch64.img.bz2)\nwget [http://dist.gem5.org/dist/current/arm/disks/linux-aarch32-ael.img.bz2](http://dist.gem5.org/dist/current/arm/disks/linux-aarch32-ael.img.bz2)值得一提的是最新的预编译文件中并不包含 dtb 文件，原因是官方不建议手动指定因为 gem5 20.0+ 版本能够自动生成，当然这个生成有一定的约束（VExpress_EMM 类型无法生成）。\n下载最新的 kernel 和 bootloader 文件使用如下命令：\nbash# 下载至当前目录（fullsystem）\nwget [http://dist.gem5.org/dist/v22-0/arm/aarch-system-20220707.tar.bz2](http://dist.gem5.org/dist/v22-0/arm/aarch-system-20220707.tar.bz2)\n# 解压至当前目录（包含两个文件夹binaries和disks）\ntar jxvf aarch-system-20220707.tar.bz2下载最新的 disk 镜像使用如下命令：\nbash# 下载至当前目录（fullsystem）\nwget [http://dist.gem5.org/dist/v22-0/arm/disks/ubuntu-18.04-arm64-docker.img.bz2](http://dist.gem5.org/dist/v22-0/arm/disks/ubuntu-18.04-arm64-docker.img.bz2)\n# 解压至当前目录**并会删除原压缩文件**\nbzip2 -d ubuntu-18.04-arm64-docker.img.bz2值得注意的是选择镜像时，要考虑目标应用对操作系统的要求，在该下载页面，有许多 disk 中 Ubuntu 的版本是 14，如 aarch64-ubuntu-trusty-headless.img.bz2，这个我目前只能在进入了全系统模拟后从 terminal 中的输出看到。\n自构建组件fs.py 常用参数详细参见文件 configs/common/Option.py\nDebug-flagcpp$GEM5/build/ARM/**gem5.opt** **--debug-flags=PIM** $GEM5/configs/example/**fs.py** ...https://blog.csdn.net/qq_43381135/article/details/104433150\n简单全系统测试建议编写简单的 sh 脚本进行全系统运行，每次 terminal 打比较麻烦。\nbash# 进入GEM5目录\nvim fs.sh输入 i 进入 INSERT 模式，粘贴下列命令：\nbash#!/bin/bash\nGEM5=~/GEM5/gem5\nFS=~/GEM5/fullsystem\n$GEM5/build/ARM/gem5.opt $GEM5/configs/example/fs.py --kernel $FS/binaries/vmlinux.arm64 --disk $FS/img/ubuntu-18.04-arm64-docker.img --bootloader $FS/binaries/boot.arm64 --mem-size=4096MB --num-cpus=4按 ESC 退出 INSERT 模式，输入 :wq 写入磁盘保存\nbash# 继续在当前目录下赋予执行权限\nchmod +x fs.sh\n# 运行全系统模式\n./fs.sh与此同时，新建一个 terminal 来连接本地全系统的控制台\nbashtelnet localhost 3456如果机器允许使用 make install 命令安装软件，则进入到 gem5 的目录下输入如下命令：\nbash# 进入gem5目录\ncd ~/GEM/gem5/util/term\nmake\nmake install\n\n# 使用m5term连接\nm5term localhost 3456环境变量我看网上许多教程都使用了环境变量 M5_PATH，以及官网也提了一下，应该是方便书写 shell 命令。指定 M5_PATH 的路径，系统会自动从此路径寻找相应的内核和镜像文件（从 binaries 找 kenerl，从 disk 找 img）。但是我个人觉得没有必要，写 sh 脚本时将 kernel 和 img 的绝对路径设置好就可以直接运行，也更加灵活。下面的环境变量方法仅供参考（没有试过）：\n打开本人主机下的 .bashrc 文件，我的主机名叫 zkyh，不同的机器名称不一样\nbashvi /home/zkyh/.bashrc在最后一行添加 fullsystem 的路径：\nbashexport M5_PATH=$M5_PATH:/usr/fs-image使环境变量生效：\nbashsource /home/zkyh/.bashrc对 img 进行基本设置挂/卸载镜像更改 img 中的文件需要使用 mount 命令使得 Host 机以访问文件夹的方式访问 img 系统文件。\nGEM5 目录下创建脚本 mount.sh：\nbash#!/bin/bash\nGEM5=~/GEM5/gem5\nMNT=~/GEM5/mnt\nFS=~/GEM5/fullsystem\nsudo $GEM5/util/gem5img.py mount $FS/img/ubuntu-18.04-arm64-docker.img $MNT在进入全系统模式之前需要将镜像 umount，同目录下建立脚本 umount.sh：\nbash#!/bin/bash\nMNT=~/GEM5/mnt\nsudo umount $MNT执行 umount.sh 脚本，如果出现 umount target is busy 的问题，证明有进程占用了该分区，需要杀掉该进程。\n目前杀掉进程主要有两种方法，分别是使用 lsof 命令和 fuser 命令（虚拟机等很简单，重启就行），然而 lsof 命令我并没有在服务器上使用成功，有复杂的权限问题，而 fuser 命令（如果没有该命令需要安装包 psmisc）使用成功：\nbashsudo fuser -km /home/zkyh/GEM5/mnt扩容扩容有时非常必要，对于已经建立好的 img，因为种种原因空间不够用，需要进行扩容。\n本节主要是对于镜像 ubuntu-18.04-arm64-docker.img 扩容，因其本身不装有任何软件，预留的空间又较小（1.8G），简单编译几个 workload 就占满了，扩容比较必要。\n图形化界面方式先安装 gparted 工具：\nbash# 先要安装分区软件（磁盘管理）\nsudo apt-get install gparted开始扩展：\nbash# 向当前目录下的img写入1GB的空白空间\nsudo dd if=/dev/zero bs=1M count=1024 &gt;&gt; ./ubuntu-18.04-arm64-docker.img\n# 挂载img到分区\nsudo udisksctl loop-setup -f ./ubuntu-18.04-arm64-docker.img注意，/dev/zero 文件是一个特殊的字符设备文件，当我们使用或者读取它的时候，它会提供无限连续不断的空数据流（特殊的数据格式流）\n挂载结果如下，知道挂载到了分区/dev/loop14\n\n\n\n\n\n\n\n\n\nMapped file ./ubuntu-18.04-arm64-docker.img as /dev/loop14.\n使用 gparted 管理该分区，并最后卸载分区：\nbash# 用gparted把空闲空间加到image的sda1上，在图形化界面使用resize拉满即可\nsudo gparted /dev/loop14\n# 卸载该分区\nsudo udisksctl loop-delete -b /dev/loop14Gparted 的图形化界面如下所示：\n命令行方式命令行的方式与图形化有些许不同，需要用到工具 parted 和 resize2fs（一般系统都默认安装）。\n首先跟图形化安装类似，追加空白空间；其次对 img 使用 parted 工具管理：\nbash# 向当前目录下的img写入1GB的空白空间\nsudo dd if=/dev/zero bs=1M count=1024 &gt;&gt; ./ubuntu-18.04-arm64-docker.img\n# 使用parted工具管理img\nsudo parted ./ubuntu-18.04-arm64-docker.img进入 parted 命令界面，进行分区表的扩容：\nbash# 打印一下img的分区情况\n(parted) print\n# 控制台输出如下所示：\n# GNU Parted 3.3\n# Using /home/zkyh/GEM5/fullsystem/img/ubuntu-18.04-arm64-docker.img\n# Welcome to GNU Parted! Type 'help' to view a list of commands.\n# (parted) print                                                            \n# Model:  (file)\n# Disk /home/zkyh/GEM5/fullsystem/img/ubuntu-18.04-arm64-docker.img: 5221MB\n# Sector size (logical/physical): 512B/512B\n# Partition Table: msdos\n# Disk Flags: \n# \n# Number  Start   End     Size    Type     File system  Flags\n#  1      65.5kB  5221MB  5221MB  primary  ext4\n# 对1号分区重新分配空间，使得其占满未使用的空间\n(parted) resizepart 1 100%\n# 重新打印一下img的分区情况确认\n(parted) print\n# 退出\n(parted) quit再进入目录 ~/GEM5 下，进行扩容：\nbash# 调用之前写好的脚本将img挂载\nmount.sh\n# 查看本机分区情况，找到img被挂载的分区\ndf -h\n# 控制台打印如下：\n# Filesystem      Size  Used Avail Use% Mounted on\n# udev            184G     0  184G   0% /dev\n# tmpfs            37G  3.0M   37G   1% /run\n# ...\n# /dev/loop17     4.8G  1.5G  3.1G  32% /home/zkyh/GEM5/mnt\n# 对该/dev/loop17分区进行扩容\nsudo resize2fs /dev/loop17\n# 重新查看分区情况以确认\ndf -h\n# 调用之前写好的脚本卸载img，结束扩容\numount.sh安装软件对于预构建或者自行创建的 img 来说，文件系统中安装的包非常少，特别是上述使用的 ubuntu-18.04-arm64-docker 镜像，里面没有安装任何软件，连基本的 gcc 和 make 都没有，需要使用者自行安装。最好使用 chroot 的方式安装软件，不推荐在全系统模式下进行软件的安装，因为这会非常慢。\nGEM5 目录下建立 app-install.sh 文件：\nbash#!/bin/bash\nMNT=~/GEM5/mnt\nsudo /bin/mount -o bind /sys $MNT/sys\nsudo /bin/mount -o bind /dev $MNT/dev\nsudo /bin/mount -o bind /proc $MNT/proc\n# 连接网络需要，域名解析\nsudo cp /etc/resolv.conf $MNT/etc/进入目录~/GEM5/mnt 当中，执行以下命令：\nbashsudo chroot .在 x86 的 Host 机下对 arm 架构的文件系统进行 chroot 命令，大概率会出现以下错误：\n\n\n\n\n\n\n\n\n\nchroot: failed to run command ‘/bin/bash’: Exec format error\n大概率是 Host 机和 img 的架构不兼容，要么是 arm 和 x86 不兼容，要么就是 32 位和 64 位不兼容，32 位和 64 位不兼容好解决，下载位数对应的 img 即可，而 arm 和 x86 的不兼容需要进行一定设置。\n比如使用 x86Host 机，arm64 架构的 img，需要安装 qemu-user-static，这是 QEMU 用户模式下的 arm 仿真器。通过 qemu-arm-static，可以在 x86 的 Host 机上模拟 arm 处理器，就像运行在 arm 上一样进行各种操作。\n安装该软件，并将 qemu-aarch64-static 文件复制到 img 中：\nbashsudo apt-get install qemu-user-static\n# 64位执行下面命令\nsudo cp /usr/bin/qemu-aarch64-static ~/GEM5/mnt/usr/bin\n# 32位执行下面的命令\n# sudo cp /usr/bin/qemu-arm-static ~/GEM5/mnt/usr/bin现在可以正常 chroot。\n完成 chroot 命令后进入到 img 的根目录中，需要对软件源做一些基本配置：\nbashapt-get update\n# 安装一些非常基本的命令，比如下面将要用到的add-apt-repository\napt-get install software-properties-common\nadd-apt-repository universe\napt-get update在此基础上设置更新软件源并安装一些常用软件：\nbashadd-apt-repository ppa:ubuntu-toolchain-r/test\napt-get update\napt-get install gcc-9 g++-9 make wget git vim --fix-missing上面在添加源的时候，可能会遇到添加失败的情况：\n\n\n\n\n\n\n\n\n\nERROR: user or team does not exist\n一般是证书出了问题，需要重新安装。\n默认安装的 gcc 版本是 7，这里需要使用 gcc-9 才能安装 9 以上的版本，但是此操作会在环境变量中添加 gcc-9/g++-9 的命令而不是 gcc/g++ 本身，需要建立动态链接：\nbashcd /usr/bin\n# 如果之前安装了gcc/g++，要先删除\n# rm gcc g++\n# 建立动态链接，将gcc9/g++9链接至gcc/g++\nln -s gcc-9 gcc\nln -s g++-9 g++安装完毕退出 chroot，umount 镜像。\n修改 umount.sh 方便后面的执行：\nbash#!/bin/bash\nMNT=~/GEM5/mnt\nsudo umount $MNT/proc\nsudo umount $MNT/dev\nsudo umount $MNT/sys\nsudo umount $MNT执行下列命令：\nbashexit\n./umount.sh配置代理配置代理和普通 Ubuntu 配置类似，注意要安装 curl 工具（同时保证基本的联网），以及良好的开关 proxy 和服务的习惯\nbashapt-get install curl --fix-missingCheckPoint","slug":"gem5 基本部署","date":"2023-12-29T07:09:04.000Z","categories_index":"工程技术","tags_index":"Gem5","author_index":"Lucas Zhang"},{"id":"e11309200b51d3994997c0a4fbb9bd23","title":"Linux:远程服务器基本配置","content":"基本配置Linux 远程服务器通过跳板机访问内网服务器本地机器的配置详见下面的文件：\n注意跳板机 IP 地址和服务器 IP 地址不一样，跳板机作用是让本地机器访问内网，因此配置 VPN 这里需要填入跳板机的 IP 地址。预共享密钥和密码不是同一个东西，这里我的预共享密钥是 lab505，用户名是 zkyh，密码是 ac3bdf92。密码用于服务器的登录等。\n连接上 vpn 后，用终端连接服务器，这里推进 vscode 的 Remote-SSH 插件，接下来也基于该插件讲解。\n\n\n初次连接时，会要求配置 config 文件，在目录 C:\\Users\\用户名\\.ssh 下，其内容如下：\n\n\nHost 和 HostName 都配置成服务器的 IP 地址，User 就是用户名 zkyh。选择服务器系统 linux，配置完后完成连接。\nssh 免密登录假设需要使用 Windows 客户机 A 免密登录远程 Linux 服务器 B，其本质就是在 A 上生成 rsa 公私钥对，将公钥添加到服务器 B 上即可。\n生成公私钥：\nbashssh-keygen -t rsa -C \"1536454795@qq.com\"与后面 git 内容保持一致，一般用邮箱进行注释，执行命令后需要进行 3 次或 4 次确认：\n\n\n在 B 的~/.ssh/目录下输入命令：\nbash# ID_RSA.PUB是A上的公钥id_rsa.pub的内容，将该内容追加进文件authorized_keys（没有该文件会新建）\necho \"ID_RSA.PUB\" &gt;&gt; authorized_keys\necho \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCoJkMyoTQ58Bn9EXzzesPI9GCifSwhoJy+wzsrG7hGqQ1FtdZ/kzxWypO5rbmp7MNb7LP/01bINI/I1n2bF6N6eA0tJglN9i100t21TsmfuWe6X+FyTj7qyLX2rpeAa3O6n+XoklGtMsIZATMx8Jw4LPZYEq46I9l191kt/QSO6eNE3U+KLhvFXAzS/6Ok8ay9Qo4JXTaUjJCocTCMHpZsq1rw8OMowQUAtKyjRMZvHPg5QLyGAypAWWIn6yNH1aiU4OyyOJjOD8u3gg/44dqbFiiV7JT++zM7JwHD4HlkoO0/5D6n8NPI+PMtXcfTDHVjAekj44KaomIoYpG2vqMGUztyI46qQGmJGC/RZTtMDjZMB6l+i1ZlZ4Wck/hIZiiuzHaWnXBZBsNgfxKdOPWQYRx1rtl8awHICvd2XFteFw8xyzHHrH9SqZwSYM5ImuJWLxwPzMKZsVmRvQ50ICKfOYjjHyl60m5PUV8S7d1BzT1uMOPJqPpEHf4PfoA75rU= 1536454795@qq.com\"  &gt;&gt; authorized_keys文件传输文件传输有许多方法，如果本地机器有图形化界面，推荐使用 vscode 进行传输，否则还是基于 ssh 加密的两种方法：scp 和 sftp。本次 terminal 中的命令示例都是基于本地服务器 Windows 和远程服务器为 Linux 的情况，可以从命令中路径的间隔符判别是 Windows 的路径还是 Linux 的路径（Windows 是反斜杠 \\，Linux 是正斜杠 /）。所有 terminal 的命令都是在 Windows 上发起的，因此 Windows 路径都是相对 terminal 工作目录的，而 Linux 则是相对用户目录 ~ 的。\n指定远程 Linux 服务器都会使用**&lt; 用户名 &gt;@&lt;IP 地址 &gt;**的形式，本小节遵循该方式。\n本小节分大文件和小文件的传输讨论传输手段，由于内网穿透原因，大文件的传输可能不稳定。如何界定大文件和小文件本身是一件模糊的事情，这里经过本人的实验，小于等于 512MB 的文件是可以通过 scp 稳定传输的 ，因此认为是小文件，大于 512MB 的文件传输不稳定，认为是大文件。注意大文件小文件的界定是根据网络情况来的，如果没有内网穿透可能不存在传输不稳定问题。\n小文件的传输文件传输建立在上述 ssh 免密登录的前提下，使用 scp 命令进行文件的拷贝：\nbash**scp** -r file zkyh@10.77.110.155:upload/\nfile 代表待上传的文件或文件夹\n-r 代表允许传输文件夹\nzkyh 代表用户名\n10.77.110.155 代表服务器 IP 地址\nupload 代表相对于 ~ 的上传位置（目标路径）\n\n相应地，将服务器上的文件（夹）下载至本机即可使用下面的命令：\nbash**scp** -r zkyh@10.77.110.155:file download\\\nfile 代表相对于 ~ 的待下载文件（夹）\n-r 代表允许传输文件夹\nzkyh 代表用户名\n10.77.110.155 代表服务器 IP 地址\n.\\download 代表下载到本机的目录\n\n大文件的传输大文件的传输推荐使用 sftp 命令（没有试过 scp，应该也可以），需要先建立 sftp 连接，再使用 put 和 get 方法进行文件的传输：\nbash# 建立sftp连接\n**sftp** zkyh@10.77.110.155\n# 使用put上传文件，上传file到Linux的upload目录\n**put** -r file upload/\n# 使用get下载文件，下载file到Windows的download目录\n**get** -r file download\\值得注意的是 sftp 是支持断点续传的，因此网络不稳定，出现 broken pipe 的错误也没有问题，只需要重新建立 sftp 连接，使用 reput/reget 命令即可：\nbash# 建立sftp连接\n**sftp** zkyh@10.77.110.155\n# 使用reput实现断点续传\n**reput** -r file upload/可以看下面的示例：\n\n\nvscode 直接拖拽直接基于 GUI 的方式将文件（可以是大文件）拖入已经建立 ssh 连接的 vscode 文件导航栏中，vscode 会在后台完成复制。这种方式似乎只能由客户端向服务端上传文件/文件夹，但是连接比较稳定。\n文件暂存网站国内国外有许多提供文件暂存服务的网站，这是一个文件传输的很好的中转站，其对于拥有图形化界面拥有浏览器的 Linux 系统比较方便，但是若没有图形化界面，似乎不可用：因为这些网站的上传下载都是基于 javascript 的，需要自行写请求体。至于能否使用 curl、wget 等下载工具去下载还有待研究。\n使用 aria2 进行下载：\n使用 vscode 进行服务器端开发除了上述使用 vscode 连接远程服务器，vscode 还可以进行服务器端的开发，只需要在服务器端安装插件即可：\n\n\n上述图中的 LOCAL-INSTALLED 表示的是本地的插件，可以点击 Install in SSH：10.77.110.155 安装到服务器端，这样在下面的 SSH：10.77.110.155-INSTALLED 能够显示。\nssh 连接后，vscode 的插件的运算负载就会被放在服务器上而不是本地，甚至 vscode 本身的一些功能，比如左侧栏的全局替换和全局搜索，负责实际去计算的也是服务器。\n其他网络问题虚拟机“掉网”有时候虚拟机会在某次开启后，无法连接互联网，这个现象我个人称之为“掉网”，从经验的角度来看，出现了一次“掉网”后频繁发生。原因未明，重新安装虚拟机可能永久解决这一现象，暂时解决可以允许下面的脚本：\nbash#!/bin/bash\nsudo service network-manager stop\nsudo cp /var/lib/NetworkManager/NetworkManager.state  /var/lib/NetworkManager/NetworkManager.state.back\nsudo rm /var/lib/NetworkManager/NetworkManager.state\nsudo service network-manager start\n# 如果不能联网就重启一下\nreboot","slug":"Linux远程服务器基本配置","date":"2023-12-27T12:02:14.000Z","categories_index":"工程技术","tags_index":"远程服务器,Markdown,文件传输","author_index":"Lucas Zhang"},{"id":"af9363059dee9d3cec07c0eec58cd7d5","title":"pimDB:From Main-Memory DBMS to Processing-In-Memory DBMS-Engines on Intelligent Memories","content":"pimDB: From Main-Memory DBMS to Processing-In-Memory DBMS-Engines on Intelligent MemoriesMotivation\n仍然是 PIM 的动机，减少数据搬移\n利用新硬件 UPMEM 构建 DBMS engine pimDB\n\nDesign\n\n\n内存数据库\n既可以 CPU-DRAM 方式工作，也可以 DPU-UPMEM 方式工作\n两种 Page Format：\n\n\n\nEvaluation\nIntel Xeon Silver 4110 CPUs （16 核 32 线程）\n125GB of DRAM（非 PIM）\n20 PIM DIMMs（2560 DPUs，160GB memory)，因故障实际上只有 2496 DPUs 可用\nTPC-H orderline table\n\nTPC-H\nTPC-H 是用来评估在线分析处理的基准程序，主要模拟了供应商和采购商之间的交易行为，其中包含针对 8 张表的 22 条分析型查询\nTPC-H 模型是典型的雪花模型，一共有 8 张表，其中 nation（国家）和 region（区域）两张表的数据量是固定的，其余 6 张表的数据量跟比例因子 SF（Scale Factor）相关，可以指定为 1,100,1000 等，分别代表 1 GB、100GB、1000GB，根据指定的 SF 确定每张表的数据量\n\n\n实验\nCPU 线程\nDPU 个数\nTasklet 数\nDMA Transfer size\nPage format\nSF\noperation\nselectivity\nattribute 个数\n物化策略\n\n\n\n1\n变量\n变量(CPU 未知)\n11\n没说\n变量\n变量\nscan-and-select\n50%\n1\n/\n\n\n2\n变量\n变量(CPU 未知)\n11\n没说\n变量\n1\nscan-and-select\n50%\n1\n/\n\n\n3\n32\n64\n11\n变量\n变量\n变量\nscan-and-select\n50%\n1\n/\n\n\n4\n没说(32)\n变量\n没说(11)\n没说\n变量\n变量\nscan-and-select\n50%\n没说(1)\n/\n\n\n5\n没说(32)\n64\n变量\n变量\n变量\n8\nscan-and-select\n50%\n没说(1)\n/\n\n\n6\n没说(32)\n64\n11\n32B\n变量\n没说\nAggregation\n50%\n变量\n/\n\n\n7\n没说(32)\n64\n11\n64B\n变量\n1\nscan-and-select\n变量(DPU 变时 50%)\n\n变量\n\n\n8\n\n变量\n\n\n变量\n\n变量\n\n\n\n\n\n\n数据在 PIM 内存中是如何分布的？平均？\nDPU 的空间够吗？（640 个 DPU 怎么装 80GB）（8 个 DPU 怎么装 1GB）\n\n实验 1 CPU vs PIM\n\n\n实验\nCPU 线程\nDPU 个数\nTasklet 数\nDMA Transfer size\nPage format\nSF\noperation\nselectivity\nattribute 个数\n物化策略\n\n\n\n1\n变量\n变量(CPU 未知)\n11\n没说\n变量\n变量\nscan-and-select\n50%\n1\n/\n\n\n\n\n\nPIM 的成倍增加，性能几乎是成倍增加的；CPU 的成倍增加，在个数少时性能基本成倍增加，个数多时不然（shared nothing，减少竞争）\n数据量的增加对于 PIM 的影响几乎线性；而对 CPU 性能影响较大（减少数据移动，或者高速化并行化数据移动）\nPAX 的方式优于 NSM 的方式（列存储适合 OLAP 的必然）\n\n实验 2 Impact of Invocation\n\n\n实验\nCPU 线程\nDPU 个数\nTasklet 数\nDMA Transfer size\nPage format\nSF\noperation\nselectivity\nattribute 个数\n物化策略\n\n\n\n2\n变量\n变量(CPU 未知)\n11\n没说\n变量\n1\nscan-and-select\n50%\n1\n/\n\n\n\n\n\n何为 invocation cost？个人认为，比如执行 select A from B where A &gt; 30，传输 30 这个数据造成的开销就是\n合理划分任务与数据的 UPMEM 应用中 invocation cost 忽略不计；invocation cost 是存在的，开发者需要合理分配任务\n一个 DIMM 有两个 rank，每个 rank8 个 chip，每个 chip8 个 DPU，一个 DIMM 的并行计算能力优于 CPU\n\n实验 3 Page Format、WRAM and Data Movement\n\n\n实验\nCPU 线程\nDPU 个数\nTasklet 数\nDMA Transfer size\nPage format\nSF\noperation\nselectivity\nattribute 个数\n物化策略\n\n\n\n3\n32\n64\n11\n变量\n变量\n变量\nscan-and-select\n50%\n1\n/\n\n\n\n\n\n64B 一个 tuple\n\n个人定性判断：DMA tansfer 所需的时钟还是多的，NSM 每次 DMA 传输的有效数据可供执行的指令非常少，整体来看 I/O 花费的时钟周期占比较大，因此 IPC 就低；而 PAX 每次 DMA 传输的有效数据非常多，一次 DMA 可以执行非常多的指令，整体来看用于计算的时钟周期占比较大。\n\nSF 的指标仍然是表现的扩展性和稳定性良好\n\nPAX 的方式需要更少的数据搬移，因此无论一次性传多少字节到 WRAM 中，数据远远足够，表现计算瓶颈\n\nNSM 的方式需要更多的数据搬移，表现为 IO 瓶颈（一次搬运的数据很小，计算占比很小，需要等下一次 I/O）\n\n32B 有最小的读放大\n64B 是一整个 tuple\n128B 是两个 tuple\n\n\n合理设计数据布局提高数据搬移效率，合理调整 DMA transfer 大小\n\n\n实验 4 Scalability and Constancy\n\n\n实验\nCPU 线程\nDPU 个数\nTasklet 数\nDMA Transfer size\nPage format\nSF\noperation\nselectivity\nattribute 个数\n物化策略\n\n\n\n4\n没说(32)\n变量\n没说(11)\n没说\n变量\n变量\nscan-and-select\n50%\n没说(1)\n/\n\n\n\n\n\n将数据量和 DPU 个数按照同样的比率增加，表现不变（数据平均分布）\n将数据量恒定，将 DPU 个数按照一定的比率增加（2 倍），执行时间按照同样的比率减少\n可扩展性和稳定性很好\n\n实验 5 Tasklet\n\n\n实验\nCPU 线程\nDPU 个数\nTasklet 数\nDMA Transfer size\nPage format\nSF\noperation\nselectivity\nattribute 个数\n物化策略\n\n\n\n5\n没说(32)\n64\n变量\n变量\n变量\n8\nscan-and-select\n50%\n没说(1)\n/\n\n\n\n\n\nPAX 模式由于计算瓶颈，因此 DMA transfer sizes 几乎没影响；DMA 对于 NSM 模式的影响与之前的 Page Format 类似，32B 相对最好，64B 最差，128B 次之\n多 tasklet 能够充分利用 I/O 时间 interleave，提高计算效率\nPAX 模式于 12tasklet 饱和，NSM32B 于 8，NSM64B 和 NSM128B 都于 6 饱和\ntasklets 个数要合理，太多可能过分占用 WRAM 空间\n\n实验 6 Projection and Aggregation\n\n\n实验\nCPU 线程\nDPU 个数\nTasklet 数\nDMA Transfer size\nPage format\nSF\noperation\nselectivity\nattribute 个数\n物化策略\n\n\n\n6\n没说(32)\n64\n11\n32B\n变量\n没说\nAggregation\n50%\n变量\n/\n\n\n\n\n\n引入多个 attribute 并对每个 attribute 进行 aggregation\n文中说到 NSM 能够一个 DMA Transfer 传输所有 attribute，因此增加 attribute 不会造成太大影响（I/O bounded），相反能够让 IPC 提高\nPAX 每次 DMA 拿到部分 mini page，要想完成上述计算就需要多次 I/O，但是每次 I/O 带来的计算任务还是足够多的，因此仍然是 computation bounded，IPC 会随 attribute 的增加减少，但减少的不多；此外，由于引入多 attribute 的 aggregation 增加了计算任务，对于 computation bounded 的 PAX 来说，仍然会造成性能的影响（多一个 attribute 多执行 6~8ms）\n之前一直处于劣势的 NSM 反而在这种情况下的执行时间处于优势，这是 OLTP 和 OLAP 两种应用适用不同 page format 的必然，因此需要根据应用来设计程序，Trade off between computation and I/O\n\n实验 7 Materialization\n\n\n实验\nCPU 线程\nDPU 个数\nTasklet 数\nDMA Transfer size\nPage format\nSF\noperation\nselectivity\nattribute 个数\n物化策略\n\n\n\n7\n没说(32)\n64\n11\n64B\n变量\n1\nscan-and-select\n变量(DPU 变时 50%)\n\n变量\n\n\n\n\n\nMaterialization，个人认为其意思是将一些复杂查询的结果持久化到硬盘中以便下次使用\n增加 selectivity 会增加物化结果的大小（多少）\n对于 BitVector，其只记载 tuple 的 location 而不记载真正的 tuple，在 WRAM 中缓存（不占内存）\n对于 Full Materialization，需要记录所有 attribute，且在 MRAM 中缓存（占内存）\n对 NSM，BitVector 方式几乎没有影响（I/O bounded），Full Materialization 方式会需要写入 MRAM，会有轻微影响（64B 刚好是一个 tuple）\n对 PAX，BitVector 方式有轻微影响（computation bounded），Full Materialization 方式有着极大的影响，因为需要所有 attribute，而 PAX 只会缓存部分 mini page，因此需要 I/O 去读其他的 attribute\nScalability 和之前一样\n\n实验 8 Kernel deployment and invocation\n\n\n大的通用性高的 kernel（程序）vs 小的专用性高的 kernel（程序）\n大的需要传额外的参数以判断操作类型，小的可能需要切换不同的 kernel 完成操作\n文章认为 24KB 的 IRAM 足够放置大的通用性高的 kernel，传参数的开销小于传 kernel 的开销，但是如果应用条件允许的话，传 kernel 也是可以接受的选择\n\nLessons\nHow will PIM-capable memories be embedded into the memory hierarchy?\nWill they potentially co-exist with passive memories building a multi-tier main-memories or is it realistic to assume PIM-only memory?\nHow will PIM-memories scale and what interconnect will they have, especially with view of novel cachecoherent interconnects such as CXL and protocols like CXL.mem?\n\nContribution\nWe investigate the impact of different page layouts (NSM, PAX) on PIM processing and scalability on a real system. We observe the necessity for custom PIM page layouts.\nWe investigate the scale and the different levels of PIM-parallelism. Our exploration offers insights into the compute/bandwidth tradeoffs in PIM-processing and calls for compute/transfer interleaving primitives in PIM settings.\nWe investigate the effect of the in-situ/PIM memory hierarchy and configurable PIM data transfers (as opposed to cachelinesized transfers) on assumptions in cache-aware processing and data layouts.\nWe investigate PIM allocation strategies, as PIM mandates data/ operation co-placement and partitioning. In this context, we evaluate the kernel deployment and the PIM invocation overhead.\n\n","slug":"pimDB  From Main-Memory DBMS to Processing-In-Memory DBMS-Engines on Intelligent Memories","date":"2023-11-28T11:02:22.098Z","categories_index":"工程技术","tags_index":"页面布局,内存层次结构,数据迁移","author_index":"Lucas Zhang"},{"id":"c1ec9505ed5e2baed7a2c980a22bec5a","title":"正向代理","content":"正向代理基本原理流量转发基于上面的原理，现使用 shadowsocks 工具实现代理服务器的流量转发\n服务端在 Ubuntu22.04 上安装 shadowsocks：\nbashsudo apt-get install shadowsocks-libev写一个配置脚本 shadowsock.json 配置代理的端口号和密码（主要是这两个）：\njson{\n    \"server\":[\"::0\",\"0.0.0.0\"],\n    \"server_port\":1080,\n    \"local_port\":1080,\n    \"password\":\"123456\",\n    \"timeout\":60,\n    \"method\":\"aes-256-gcm\",\n    \"mode\":\"tcp_and_udp\",\n    \"fast_open\":false\n}在同级目录下写一个启动脚本：\nbashss-server -c ./shadowsocks.json -f start\n-c 的意思是指定配置文件（json）\n-f 的意思是以守护线程的方式运行，后面需要接参数 pid file，这里省略的话会默认在同级目录下新建一个 start 文件存放进程的 pid\n\n同级目录下再写一个关闭脚本 shutdown.sh 如下：\nbash#!/bin/bash\n\n# 读取start文件中的PID\npid=$(cat start)\n\n# 检查PID是否存在\nif ps -p $pid &gt; /dev/null; then\n    # 进程存在，关闭它\n    kill $pid\n    echo \"进程已关闭\"\nelse\n    # 进程不存在\n    echo \"进程不存在\"\nfi或者用暴力办法，查进程强行 kill 即可：\nbash# 查ss-server的进程，一般是两个，删掉自己运行的那个（注意看命令行信息）\nps -ef | grep [s]s-server\n# 强制kill掉就行\nkill -9记得为两个脚本赋权：\nbashsudo chmod +x start.sh\nsudo chmod +x shutdown.sh开机自启本人查过大量的网上资料，也动手实践过，目前并未找到非常好的方法实现开机自启，可能的原因包括但不限于：\n\n开机自启的方法问题（简单的脚本我开机自启成功过）\nshadowsocks-libev 的版本问题（可以快速试一试，去 github 的 shadowsocks 官方）\nshadowsocks 本身的问题（开源项目，背后可能没有公司维护）\n\n因为服务器一般不关机，就让程序一直运行即可，必要的时候查进程号给 kill 掉就行：\n同时注意要在防火墙放行端口，具体的方式可以在下面的机场代理小节查看\n客户端安装 shadowsocks GUI 客户端，windows 平台可以安装下面仓库的便携版：\n\n\n\n\n\n\n\n\n\ngithub 上找了大半天，基于命令行的挺多的，基于 GUI 的基本上都是上面的仓库，也有 Debian 上 GUI 的，但是 Debian 上为何不基于命令行？基于 GUI 的大多数是便携版，也能开机自启，够用了\n右键点击图标，点击“服务器”，点击“编辑服务器”，填入代理地址信息：\n\n\n\n\ncppipv6 address: 2401:ec00:15:1008:f2d4:e2ff:fee7:8004\nprot: 1080勾选“全局模式”，然后可以在“帮助”里选择“显示日志”查看流量转发情况。\nAPP 代理启用了上述代理后，一般浏览器都是可以正常代理的，一般软件都是不可以代理的。想要让软件的流量也被转发到代理服务器，一般通过软件自己的设置走代理，具体如下：\n\n\n这样的方式是比较简洁的方式，但是有的软件不提供代理，比如阿里云盘，这个时候就需要进行非常底层的全局代理软件来实现。\n最绝对的方式是透明代理，也就是在路由器上设置代理，目前没有硬件条件无法实现。\n最底层的代理软件似乎是 SSTap，它是通过建立虚拟网卡，将应用的流量走虚拟网卡，在虚拟网卡出对流量进行代理，但是好像对 Shadowsocks 的支持不是很好（对 ShadowSocksR 的支持较好？），我自己目前没成功，以后可以探究一下 ou_7f6ee51dd49317f10f80a0409adf4dc7\n目前使用成功的代理软件是 Proxifier，可以代理许多常用的软件（有些软件还是无法代理，比如 ToDesk）\n需要合理设置软件完成代理，在此之前，可以先不考虑连通性而关闭 ShadowSocks 的代理。下面将主要配置软件菜单栏的 Profile 部分：\n\n\nIPV6 绕过校园网一般来说，校园网通过学号和 IPV4 计费，但是一般使用 IPV6 发流量校园网将不计分；基本原理是找一台支持 IPV6 的代理服务器，客户端将 IPV6 流量发送到服务器上，服务器将 IPV6 流量转为 IPV4 发送给目标服务器，再取回。\n值得一提的是，购买的机场服务器，是默认支持 IPV6 的，可以正常进行转发（个人购买的机场链接不支持 ShadowSocksR，进而使用 clash），配置如下：\n\n\n更厉害的校园网白嫖方法见博客（涉及非常细节和底层的网络原理）：\n曲线“翻墙”正向代理的很大一个用处就是“翻墙”，“翻墙”主要是指访问 github 和 google，而此处的“曲线救国”是指在目标机器不配置代理的情况下，如何拿到上述两者的资源。但是如果需要访问墙外的资源，无论如何还是需要“翻墙”，只不过是直接和间接的区别。\ngitee 中转对于 github 的仓库，其实很简单可以通过 gitee 进行转存，可以直接用 url 转存，也可以 gitee 绑定 github 账号，先用 github 账号 fork 之后再转存。这样做的好处就是目标机器会比较干净，且基于图像界面的操作虽然繁琐却比较简单。缺点就是在编译某些仓库时，会有许多依赖项需要去 github 上拉取，如果手动一个一个转存会非常花时间。\ngitee 还可以看作一个中转站，不仅仅可以用于中转代码，还可以用于中转编译后的 obj，普通文件等等。但是其一次 push 的大小有限制，仓库的大小也有限制。\n修改 hosts 访问 github国内无法访问 github 的原因主要是 DNS 污染，可以通过使用工具查询 github 网站正确 IP，修改 hosts 文件实现访问 github。\n首先使用 IP 查询工具分别查询下面两个域名的 IP 地址：\nbash# 适用于 https方式的克隆\ngithub.com\ngithub.global.ssl.fastly.net查询得到地址后，修改 hosts 文件：\nbash# Linux的 hosts文件目录\n/etc/hosts\n# Windows的 hosts文件目录\nC:\\Windows\\System32\\drivers\\etc\\hosts在本机环回地址 localhost 后面添加上述的两个域名以及其 IP（需要管理员权限，linux 下使用 sudo vim 进行编辑）：\ntxt127.0.0.1       localhost\n**20.205.243.166  github.com**\n**199.96.58.15    github.global.ssl.fastly.net**修改后刷新 DNS 缓存：\nbash# Ubuntu下\nsudo /etc/init.d/dns-clean start\n# Windows Terminal下\nipconfig /flushdns注意，上述手动方式修改 hosts 的方法虽然简单干净，但是由于 IP 地址时常发生变化，上述修改过一段时间后就容易失效，需要重新手动修改，会比较麻烦。网上会有一些自动刷新的脚本可以参考，但本人没有试过。\n虚拟机流量转发如果是使用的虚拟机，则可以让 Host 机转发虚拟机的流量，如果 Host 机可以访问外网，则虚拟机也可以访问外网。\n本质上是使用 Clash For Windows 等代理软件的“Allow LAN”功能，因在 Windows 上配置代理相比 Linux 要简单得多：\n\n\n打开上述功能，同时可以看到代理端口是 7890，现找到虚拟机的 IP 地址，输入 win+r，打开 cmd，输入 ipconfig\n找到 VMware Network Adapter VMnet8（默认使用 VMware 配置虚拟机，且网络方面是默认配置），其中 IPv4 的地址就是虚拟机的 IP 地址：\n\n\n进入 Ubuntu（其他 Linux 发行版应该也是类似的流程），打开设置-&gt; 网络设置-&gt; 网络代理（不同系统名字会有些许差异，但大体意思都一样，就是代理的意思，注意不是VPN，是代理！！！），然后手动添加 HTTP 和 HTTPS 代理，IP 地址和端口如上所述：\n\n\n上述操作可以在 Chrome 等浏览器中可以访问外网，但有时需要终端走代理（如 pip、apt-get、yum 等），这时针对需要走代理的用户做如下设置：\nbashexport http_proxy='http://192.168.112.1:7890'\nexport https_proxy='http://192.168.112.1:7890'\nexport ALLOW_PROXY='http://192.168.112.1:7890'如果只在 terminal 输入上述结果，只会当前 terminal 生效，需要永久生效则需要写入 ~/.bashrc 文件中\nbashvim ~/.bashrc\n# 输入下面内容，使用wq保存退出\n# export http_proxy='http://192.168.112.1:7890'\n# export https_proxy='http://192.168.112.1:7890'\n# 使立即生效\nsource ~/.bashrc机场代理真正要访问外网，还是需要外网服务器。可以自行去 Vultr 购买，然后类似上面流量转发配置自己的服务器（注意防火墙放行端口）。还有一种是购买代理服务，也就是常说的“机场”，机场会为用户配置好代理服务器，用户只需用代理工具连接即可。\n机场代理需要首先订阅机场链接；使用的代理软件是 clash 的 linux 版本，并且整合 clash 的 GUI 组件 yacd（ClashDashboard），具体的信息可以自行查看 github 仓库 clash-for-linux。\n这里以阿里云 ECS 服务器为例，介绍如何为远程服务器配置代理。\n基本使用克隆仓库：\nbash# 可以访问github使用下面的链接\ngit clone https://github.com/wanhebin/clash-for-linux.git\n# 无法访问github使用本人公开的仓库\ngit clone https://gitee.com/failurejack/clash-for-linux.git设置订阅链接和密码：\nbashcd clash-for-linux\nvim .env\n\nCLASH_URL 处粘贴为你个人的订阅地址，CLASH_SECRET 处写上 ClashDashboard 的登录密码，如何此处为空，将随机生成字符串，并在后面的启动中打印到控制台。\n\n\n启动 clash-for-linux\nbash# 这里确保要使用 sudo 和 bash 执行\nsudo bash start.sh正常情况下终端打印如下：\n\n\n可以看到 GUI 的密码和地址在控制台中被打印出来，有关 Dashboard 的问题，将在下一小节“GUI 配置”叙述。\n先查看各种服务进程是否已经启动：\nbashnetstat -tln | grep -E '9090|789.'正常情况结果如下：\n\n\n上述四个端口号代表的进程都启动时，证明连接已经建立，此时只需要将流量代理到 http://127.0.0.1:7890 即可。由于在远程服务器上主要使用 terminal 工作，因此这里介绍如何在在 terminal 中开启代理。\n与“虚拟机流量转发”章节中类似，在 terminal 代理流量分为暂时性代理和永久代理。暂时性代理只会在当前 terminal 生效，新建或切换为其他 terminal 都无效，具体方法就是输入如下代理命令：\nbashexport http_proxy='http://127.0.0.1:7890'\nexport https_proxy='http://127.0.0.1:7890'永久生效就是将上述内容写入 ~/.bashrc 文件末尾。\n然而，有时候需要频繁开关代理，因此 clash-for-linux 采用了更为方便的方法（其实就是写了 shell 脚本）：\nbash# 加载环境变量\nsource /etc/profile.d/clash.sh\n# 开启代理\nproxy_on\n# 查看环境变量中的代理\nenv | grep -E 'http_proxy|https_proxy'即加载 /etc/profile.d/clash.sh 脚本文件中所设置的环境变量，以便在当前 shell 会话中使用。这个文件定义了 proxy_on 和 proxy_off 两个函数供调用，可以方便地开关代理（注意是当前 terminal 生效）。正常情况输出如下：\n\n\n如果换了 terminal，只需要输入命令 source /etc/profile.d/clash.sh 即可正常使用。此时可以科学上网：\n\n\n由于服务器重启次数较少，因此 clash 的四个进程可以保持开启，若是重启了服务器，重启该进程即可（代理进程一般也没多重要），没必要配置开机启动、守护进程等。这简单介绍一下服务的关闭：\nbash# 这里确保要使用 sudo 和 bash 执行，**注意一定是shutdown.sh而不是shutdown，shutdown是关机**\nsudo bash shutdown.shGUI 配置上述命令行的配置是通用的，一般而言配置成功后机场会自动选择节点，可以正常科学上网。但是想要切换节点或者其他方面的应用则需要配置 GUI。\nClash Dashboard上述启动的四个 clash 的进程中，端口号为 9090 的是 Dashboard 的进程：\n\n\n如果本机有 GUI 界面，则直接打开浏览器，输入地址 http://127.0.0.1:9090/ui 访问 Dashboard：\n\n\n这里的 API Base URL 输入：http://127.0.0.1:9090，Secret 输入之前打印在 terminal 中的内容，我这里是 123456，点击 Add，会在下方新增一个带有*的区块，点击该区块进入控制界面：\n\n\n点击 Proxies 即可切换节点，点击菜单栏的其他选项可以进行更高级的配置。如果是没有图形化界面的服务器，则需要远程访问部署在服务器上的网站（需要公网 IP）。\n首先启动了 9090 端口的进程后，需要服务器的防火墙放行。一般云服务器厂商不会配置放行 9090 端口，需要自行设置，或者直接关闭防火墙：\nbashsudo ufw disable此时可以仅靠阿里云 ECS 的安全组实现流量控制，但是终归安全性不是那么高，因此下面介绍如何配置防火墙：\nbash# 先开启防火墙\nsudo ufw enable\n# 可以先看一下防火墙通过列表，查看是否允许9090端口通过\nsudo ufw status\n# 没有则允许9090端口建立tcp连接\nsudo ufw allow 9090/tcp\n\n# 可以删除已经配置的通过\n# sudo ufw delete allow 9090/tcp此时完成服务器防火墙的配置，还需配置 ECS 安全组。\n阿里云 ECS 在防火墙的基础上设置了一层虚拟防火墙，即 ECS 的安全组，需要配置放行 9090 端口。\n进入 ECS 控制台：https://www.aliyun.com/product/ecs\n点击进入目标服务器的管理界面：\n\n\n切换到安全组选项卡，点击配置规则：\n\n\nECS 默认出方向无需配置，能够从 ECS 服务器转发所有流量包，需要配置进入服务器的流量，即入方向：\n\n\n添加规则如下，注意端口范围手动输入 9090，授权对象为 0.0.0.0/0 允许任何 IP 访问，其他默认即可，点击保存。\n\n\n至此可以顺利访问 Dashboard。此时 IP 换成服务器公网 IP，使用浏览器访问 http://47.120.34.224:9090/ui，注意 IP 的不同，其他的操作跟本机上的操作一样。\n浏览器配置浏览器的代理（也许可以在.bashrc 配置全局代理），这里以 Ubuntu 桌面版预装的火狐浏览器为例，打开火狐浏览器的设置，搜索 proxy，点击 Network Settings 中的 Settings 按钮：\n\n\n进入之后，勾选 Manual proxy configuration，HTTP Proxy 输入本机回环地址 127.0.0.1，端口为 7890，勾选 Also use this proxy for HTTPS，点击 OK 即可：\n\n\n至此可以通过浏览器科学上网。\n","slug":"正向代理","date":"2023-11-25T11:13:30.102Z","categories_index":"学术科研","tags_index":"代理服务器,流量转发,正向代理","author_index":"Lucas Zhang"},{"id":"b101a6e059af61464126276089cefbed","title":"函数零点","content":"函数零点原题目是上述洛谷的题，考察二分算法，但由于有一般性，在此拿来总结。\n\n一次函数（单调函数）解析解法若已知一次函数的解析表达式，即已知中的 k 和 b 都已知，则可以之间求得唯一零点：\n\n计算解法若一次函数在某个区间[a,b]上存在零点，则一定存在一个零点，此时只需要简单的使用二分法就能解决问题，这也是其他问题的基础\n\n\n可以看到，求解一次函数的零点问题，通过在区间（假设为[-1,4]）内取端点为、，得到，故判断之间必存在一个零点。\n取两者中点为 1.5，计算得到，故取右端点为 1.5，即。重复上述过程，直至找到零点。\n精度控制值得注意的是，在二分求解时，并不是总能准确地二分到零点，即可能永远无法刚好取到零，可能总是一个非常小的数。\n一般这个时候，会规定求解精度，如保留小数点后 n 位，或是精确到 0.0001 等等，意味着比这个精确度还小的根不予考虑。常常的做法就是循环控制条件为 r-l&gt;=0.0001，如此，当 r 和 l 距离不到精确度时，继续二分得到的结果将会被舍弃，此时二分就没有必要了。\n现给出下列求解代码：\ncppdouble findRoot(double l, double r, function&lt;double(double x)&gt; f, double epsilon)\n{\n    if (f(l) == 0)\n    {\n        return l;\n    }\n\n    if (f(r) == 0)\n    {\n        return r;\n    }\n\n    while (r - l &gt;= epsilon)\n    {\n        double mid = (l + r) / 2;\n        if (f(mid) == 0)\n        {\n            return mid;\n        }\n        else if (f(l) * f(mid) &lt; 0)\n        {\n            r = mid;\n        }\n        else\n        {\n            l = mid;\n        }\n    }\n\n    return l;\n}由此可以引出零点定理如下：\n如零点定理所示，若一个函数在区间[a,b]上单调，且满足零点定理中的前提条件（连续，f(a)·f(b)&lt;0），则该函数在区间上有且只有唯一的一个零点，如何用计算方法求得这个零点，是后面问题的基础。\n上述的二分法是一个不错的方法，在最后将介绍牛顿迭代法以及其一系列改进与优化。\n\n二次函数解析解法若已知二次函数的解析表达式，即已知中的 a、b、c，可以使用求根公式来得到两个根：\n）\n\n给出求解二次方程根的函数：\ncpptypedef struct quadraticRoot\n{\n    double root1, root2;\n    quadraticRoot(double x1, double x2) : root1(x1), root2(x2) {}\n\n} qRoot;\n\nqRoot findQuadraticRoot(double a, double b, double c)\n{\n    double delta = b * b - 4 * a * c;\n\n    if (delta &lt; 0)\n    {\n        throw \"no root!\";\n    }\n\n    double root1 = (-b - sqrt(delta)) / 2 / a;\n    double root2 = (-b + sqrt(delta)) / 2 / a;\n\n    return qRoot(root1, root2);\n}计算解法二次函数在某一区间[a,b]上存在零点可以分为两种情况，一种是两个相等的根，一种是两个不等的根，如下图所示：\n\n\n二次函数的两种情况\n可以见得，无论是求解那种情况的零点（），都需要找到对称轴，当为第一种情况时（两根相同），对称轴就是零点；当为第二种情况时，在对称轴的左右区间分别执行一次函数的零点搜索算法即可。\n对称轴搜索对称轴的确定其实很简单，只要两个不同点的 y 值相同，那么这两个点就是对称的，对称轴就可以由这两个点的横坐标给出：。\n那么对于给出的区间[a,b]，当 x 分别为 a 和 b 时，有以下三种关系\n\na=b\nf(a)=f(b)\nf(a)≠f(b)\n\n显然需要搜索的是第 3 种情况，而从图中很容易发现，纵坐标绝对值大的点需要向区间内搜索。问题在于搜索步长的确定——不合适的搜索步长会使得搜索过程中，无法准确找到两个 y 值相等的点。\n然而目前没有办法于各种情况下确定合适的步长，故只能将其转化为另一种形式的二分搜索：\n\n\n\n\n\n\n\n\n\n\n令,在区间中寻找零点(唯一)\n令,在区间中寻找零点(唯一)\n\n这样搜索到了 g(x)的唯一零点 root 后（一定精度范围内），就能够得到对称轴。\n于是，对应两根相同的情况，root 就是零点。\n对于两根相异的情况，需要分别以**[a,root]、[root,b]为子区间，展开二分搜索**，继续搜索零点。\n（注：若是在找到对称点不放心仍可以提高精度二分搜索）\ncpptypedef struct quadraticRoot\n{\n    double root1, root2;\n    quadraticRoot(double x1, double x2) : root1(x1), root2(x2) {}\n\n} qRoot;\n\nqRoot findQuadraticRoot(double l, double r, function&lt;double(double x)&gt; f, double epsilon)\n{\n    double fl = f(l);\n    double fr = f(r);\n\n    if (fl == fr)\n    {\n        return qRoot(l, r);\n    }\n    else if (fl &lt; fr)\n    {\n        auto g = [=](double x) -&gt; double\n        { return f(x) - fl; };\n        r = findRoot((l + r) / 2, r, g, epsilon);\n    }\n    else\n    {\n        auto g = [=](double x) -&gt; double\n        { return f(x) - fr; };\n        l = findRoot(l, (l + r) / 2, g, epsilon);\n    }\n\n    double symmetry = (r + l) / 2;\n    double root1 = **findRoot**(l, symmetry, f, epsilon);\n    double root2 = **findRoot**(symmetry, r, f, epsilon);\n    return qRoot(root1, root2);\n}\n三次函数解析解法若已知三次函数的解析表达式，即已知中的 a、b、c、d，可以通过已知的解析信息来搜索零点\n求根公式（卡尔丹公式）卡尔丹的公式的具体推导在此不作赘述，具体看知乎推导贴\n转化为特殊型对于一元三次方程一定可以转化为下面的特殊形式：\n\n其中:\n，\n求解特殊型对于一元三次方程，给出其判别式：\n\n\n当时，方程有一个实根和一对共轭虚根。\n当 且时，方程有一个两重实根和一个单重实根。\n当 时，方程有三个互异实根。\n当时，方程有一个三重实根。\n\n给出一般情况下的求根公式：\n\n可见，计算难度相当大（手算），而用计算机计算，需要支持复数运算（四则和开方）\n在此给出其适合计算机计算的简便形式：\n\n\n\n\n ou_7f6ee51dd49317f10f80a0409adf4dc7 有时间可以实现一下复数类\n\n计算解法假设不知道需要求得零点函数的解析表达式，仅仅能够调用函数的接口 double f(double x)。\n若是知道在区间内仅有一个零点，仍然可以用基本的二分法去做，但是若是不知道区间内的零点个数或者零点个数多于一个，则只能采用暴力搜索，即以最小精度为步长，扫描整个区间。有时候，这是一份拥有极大计算量的工作。\n或是“题目”给出了额外的信息，如上述洛谷题目中给出下述信息：\n\n\n\n\n\n\n\n\n\n根与根之差的绝对值 ≥1\n则扫描步长变为了 1，在长度为 1 的区间内进行二分搜索（精度是 0.01），这样也能够加速搜索。\n半解析半计算半解析半计算是对解析与计算的一种折中。在现实中解题（尤其是算法竞赛），没有时间定义复数的运算，而可以看到在卡尔丹公式中，求解所有解一定会涉及到复数的运算（三重互异根的简便公式不涉及复数运算）。\n因此，借助解析式给出的关于函数的一些性质，优化搜索，即为半解析半计算的方式。\n三次函数有零点的情况无外乎下面三种：\n\n\n三次函数的三种情况\n\n对于第一种，即的情况，很简单，按照一次函数进行二分搜索即可\n对于第二种，即的情况，可以看到是零点也是驻点。换言之，只要能够求得该函数的驻点（这种情况一定是两个），就能够确定根的范围，再适用二分搜索即可\n对于第三种，即，与第二种类似，仍然是求驻点。\n\n对于形如的三次函数\n求导后其变为二次函数：（ⅡⅢⅡⅢ）\n如此一来该问题转化为求解上述二次函数的零点问题。而在上述三次函数求解零点中，需要求解驻点的情况中，求导得到的二次函数一定有两个零点。\n得到两个驻点后：\n对于第三种情况，直接分别在三个区间中二分搜索\n对于第二种情况，找到为零点的驻点，再确定搜索的区间，具体的确定方式很多，可以给出以下分支结构供参考：\n搜索另一个零点参考流程图\n给出代码如下：\ncpptypedef struct cubicRoot\n{\n    double root1, root2, root3;\n    cubicRoot(double x1, double x2, double x3) : root1(x1), root2(x2), root3(x3) {}\n} cRoot;\n\ncRoot findCubicRoot(double l, double r, function&lt;double(double x)&gt; f, function&lt;double(double x)&gt; fp, double epsilon)\n{\n    qRoot qR = findQuadraticRoot(l, r, fp, epsilon);\n    cRoot cR(0, 0, 0);\n\n    if (f(qR.root1) == 0)\n    {\n        cR.root1 = cR.root2 = qR.root1;\n        cR.root3 = findRoot(qR.root1, r, f, epsilon);\n    }\n    else if (f(qR.root2) == 0)\n    {\n        cR.root2 = cR.root3 = qR.root2;\n        cR.root3 = findRoot(l, qR.root1, f, epsilon);\n    }\n    else\n    {\n        cR.root1 = findRoot(l, qR.root1, f, epsilon);\n        cR.root2 = findRoot(qR.root1, qR.root2, f, epsilon);\n        cR.root3 = findRoot(qR.root2, r, f, epsilon);\n    }\n    return cR;\n}\n一般函数对于一般函数，只能采用与三次函数类似的解法：暴力扫描\n补充牛顿迭代法思想是通过不断作切线逼近零点。其算法可以描述如下：\n\n在曲线上选取初始点作切线与 x 轴交于一点 p\n在曲线上选取 x=p 的点做切线与 x 轴交于一点 q\n令 p=q，重复 2 直到找到零点\n\n下面是图形演示：\n第一次作切线（A)求与 x 轴交点                              第二次作切线（B）求与 x 轴交点\n第三次作切线（C)求与 x 轴交点                              第四次作切线（D）求与 x 轴交点\n可以看到每次作切线求 x 轴交点，就多与零点逼近一些，这是一种直觉。下面给出数学上通过严格证明的其收敛的充分条件：\n\n\n\n\n\n\n\n\n\n若 二阶可导，那么在待求的零点周围存在某一个（充分小）区域，只要起始点位于这个邻近区域内，那么牛顿-拉弗森方法必定收敛。\n同时给出其迭代公式（具体推导不阐述）：\n\n这里给出基本的牛顿迭代法的代码，初始点的选择是 (l+r)/2:\ncppdouble findRoot(double l, double r, function&lt;double(double x)&gt; f, function&lt;double(double x)&gt; fp, double epsilon)\n{\n    if (f(l) == 0)\n    {\n        return l;\n    }\n\n    if (f(r) == 0)\n    {\n        return r;\n    }\n\n    double x0, x1 = (l + r) / 2;\n\n    do\n    {\n        x0 = x1;\n        x1 = x0 - f(x0) / fp(x0);\n    } while (abs(x1 - x0) &gt;= epsilon);\n\n    return x1;\n}其收敛速度是二阶的，但仍然存在至少以下两个缺点：\n\n需要求导数\n初始点的选择很重要，一不小心就会不收敛\n\n针对上述两个缺点，对牛顿收敛法作了相关改进。\n割线法对导数部分作了改进，无需求导数，改用切线斜率代替导数，即：\n\n\n其中是上一次的迭代点，这意味着需要两个初始点作为算法的起点（第一个初始点是用来近似导数的）。\n下面给出割线法的 C++ 代码，初始点选择的是两个三等分点 (l + r) / 3, (l + r) * 2 / 3：\ncppdouble findRoot(double l, double r, function&lt;double(double x)&gt; f, double epsilon)\n{\n    if (f(l) == 0)\n    {\n        return l;\n    }\n\n    if (f(r) == 0)\n    {\n        return r;\n    }\n\n    double x0, x1 = (l + r) / 3, x2 = (l + r) * 2 / 3;\n\n    do\n    {\n        x0 = x1;\n        x1 = x2;\n        x2 = x1 - (x1 - x0) * f(x1) / (f(x1) - f(x0));\n    } while (abs(x2 - x1) &gt;= epsilon);\n\n    return x1;\n}牛顿下山法由于初始点的选取会影响算法的收敛性，故试图使用一种方法来修正迭代过程中非收敛的情况，这就是牛顿下山法。\n下面给出下山法的迭代公式：\n\n这里与普通牛顿迭代法的区别就是的引入，下面介绍下山算法来体会其作用：\n\n取，进行一次迭代计算得到\n若，则转到 3；否则，转到 4\n，转到 5\nn=n+1，转到 5\n进行一次迭代计算得到，重复 2，直到找到零点\n\n下面给出下山法的 C++ 代码，基于割线法进行了更改：\ncppdouble findRoot(double l, double r, function&lt;double(double x)&gt; f, double epsilon)\n{\n    if (f(l) == 0)\n    {\n        return l;\n    }\n\n    if (f(r) == 0)\n    {\n        return r;\n    }\n\n    double x0, x1 = (l + r) / 3, x2 = (l + r) * 2 / 3;\n\n    do\n    {\n        double lambda = 1;\n        x0 = x1;\n        x1 = x2;\n    pos:\n        x2 = x1 - lambda * (x1 - x0) * f(x1) / (f(x1) - f(x0));\n        if (abs(f(x2)) &gt;= abs(f(x1)))\n        {\n            lambda /= 2;\n            goto pos;\n        }\n    } while (abs(x2 - x1) &gt;= epsilon);\n\n    return x1;\n}","slug":"函数零点","date":"2023-11-25T11:13:30.096Z","categories_index":"学术科研","tags_index":"函数零点,解析解法,计算解法","author_index":"Lucas Zhang"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"HelloWelcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick-StartCreate a new postbash$ hexo new &quot;My New Post&quot;More info: Writing\nRun serverbash$ hexo serverMore info: Server\nGenerate static filesbash$ hexo generateMore info: Generating\nDeploy to remote sitesbash$ hexo deployMore info: Deployment\n用户自定义front由于每个md文档需要在首部生成一个特定格式的front，以供框架识别文章的元信息，包括标题、关键字、摘要、更新时间等等。如果用户仅仅是想要快速迁移博客，不想要自定义front，可以由auto.py脚本自动生成；\n同时如果用户想要自定义front，本框架依然允许，需要用户按照指定格式提前写入文件头，后面框架的处理会参考用户自定的front\n这是一个页面内跳转的示例markdown能够自动跳转各级标题，跳转方式为：跳转链接的文字，注意待跳转的标题不能存在空格，否则无法识别为跳转链接，跳转链接的文字可以存在空格\n跳 转 到he llo\n还可以通过灵活设置锚点指示跳转的位置&lt;a name&#x3D;”锚点名”&gt;&lt;/a&gt;，对于本博客，建议将锚点设置的比内容要“高一点”，锚点名同样不能有空格，跳转链接的文字同上\n跳到段落之间来跳转到第一个标题所在的位置。\n","slug":"hello-world","date":"2023-07-13T12:46:25.000Z","categories_index":"Test","tags_index":"Hello World,Beginner","author_index":"Lucas Zhang"}]